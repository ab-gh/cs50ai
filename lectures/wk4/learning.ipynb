{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# week 4: learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## supervised learning\n",
    "\n",
    "- given a data set of input-output pairs, learn a function to map inputs to outputs\n",
    "\n",
    "**classification**: supervised learning task of learning a function mapping an input point to a discrete category\n",
    "\n",
    "- given a table of data with variables `humidity` and `pressure`\n",
    "- it is supervised learning because a human has labeled each entry with `rain` or `no rain`\n",
    "- we come up with an estimated hypothesis function that maps the given data\n",
    "- we can plot these on a graph, which can be any dimension as computers are fine thinking above the third dimension\n",
    "\n",
    "**nearest-neighbor classification**: algorithm that, given input data, chooses the class of the nearest data point to that input\n",
    "\n",
    "**k-nearest-neighbor**: chooses the most common class out of `k` nearest data points\n",
    "\n",
    "**linear regression**: finding a decision boundary to classify points\n",
    "\n",
    "- given $x_1$ = Humidity, $x_2$ = Pressure\n",
    "\n",
    "$$$\n",
    "h(x_1, x_2)=\\text{Rain if } w_0+w_1x_1+w_2x_2\\ge0, \\text{No Rain otherwise}\n",
    "$$$\n",
    "\n",
    "**Weight Vector:** $\\vec w=(w_0, w_1, w_2)$\n",
    "\n",
    "**Input Vector:** $\\vec x=(1, x_1, x_2)$\n",
    "\n",
    "$h_w(x) = 1 \\text{ if } \\vec w \\cdot\\vec x \\ge0, 0\\text{ otherwise}$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## perceptron learning rule\n",
    "\n",
    "- given data point $(\\vec x, y)$, update each weight according to:\n",
    "$$$\n",
    "w_i=w_i+\\alpha(y-h_w(\\vec x))\\times x_i\n",
    "$$$\n",
    "where $\\alpha$ is the learning rate\n",
    "\n",
    "- this creates a hard-square threshold function\n",
    "- maybe you want more than 0 or 1, and care about likelyhood or confidence\n",
    "\n",
    "**soft threshold**: using a logistic function to output a *likelyhood*, not just a hard 0 or 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## support vector machines\n",
    "\n",
    "choosing a good boundary from a range of \"valid\" ones\n",
    "\n",
    "better boundaries are as far apart as possible from the two classification areas\n",
    "\n",
    "**maximum margin separator**: boundary that maximises the distance between any of the data points"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## regression\n",
    "\n",
    "supervised learning task of learning a function mapping an input point to a continuous value\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## evaluating hypotheses\n",
    "\n",
    "**loss function**: function that expresses how poorly our hypothesis performs, a loss of utility\n",
    "$$$\n",
    "L(\\text{actual, predicted})=1\\text{ if (actual = predicted)}, 1\\text { otherwise}\n",
    "$$$\n",
    "\n",
    "- we can also take into account how far away it was, using L1\n",
    "$$$\n",
    "L_1(a, p) = |a - p|\n",
    "$$$\n",
    "where `a` = actual, `p`= predicted\n",
    "- or we can use L2\n",
    "$$$\n",
    "L_2(a,p)=(a-p)^2\n",
    "$$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## overfitting\n",
    "\n",
    "- a model that fits too closely to. particular data set and may fail to generalise for future data\n",
    "- this happens if you only care about minimising loss\n",
    "- we can build a better cost functinon with Occam's razor\n",
    "- we can plenalise complexity with $\\lambda$\n",
    "$$$\n",
    "cost(h)=loss(h)+\\lambda complexity(h)\n",
    "$$$\n",
    "**regularisation**: penalising a hypothesis that is more complex in favour of simpler, more general hypotheses\n",
    "\n",
    "**holdout cross-validation**: splitting the data into a training set and a testing set, such that learning happens on the training set and is evalusated on the testing set\n",
    "\n",
    "**k-fold cross-validation**: splitting data into `k` sets, and experimenting `k` times, using each set as a test once, and using the remaining data as a training set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "# model = svm.SVC()\n",
    "# model = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results for model KNeighborsClassifier\nCorrect: 548\nIncorrect: 0\nAccuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Read data in from file\n",
    "with open(\"banknotes.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    data = []\n",
    "    for row in reader:\n",
    "        data.append({\n",
    "            \"evidence\": [float(cell) for cell in row[:4]],\n",
    "            \"label\": \"Authentic\" if row[4] == \"0\" else \"Counterfeit\"\n",
    "        })\n",
    "\n",
    "# Separate data into training and testing groups\n",
    "holdout = int(0.40 * len(data))\n",
    "random.shuffle(data)\n",
    "testing = data[:holdout]\n",
    "training = data[holdout:]\n",
    "\n",
    "# Train model on training set\n",
    "X_training = [row[\"evidence\"] for row in training]\n",
    "y_training = [row[\"label\"] for row in training]\n",
    "model.fit(X_training, y_training)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "X_testing = [row[\"evidence\"] for row in testing]\n",
    "y_testing = [row[\"label\"] for row in testing]\n",
    "predictions = model.predict(X_testing)\n",
    "\n",
    "# Compute how well we performed\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "total = 0\n",
    "for actual, predicted in zip(y_testing, predictions):\n",
    "    total += 1\n",
    "    if actual == predicted:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "# Print results\n",
    "print(f\"Results for model {type(model).__name__}\")\n",
    "print(f\"Correct: {correct}\")\n",
    "print(f\"Incorrect: {incorrect}\")\n",
    "print(f\"Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "source": [
    "## reinforcement learning\n",
    "\n",
    "given a set of rewards or punishments, learn what actions to take in the future\n",
    "\n",
    "- an agent is situated in the environment\n",
    "- the environment puts the agent in some state\n",
    "- the agent makes an action on the environment\n",
    "- the agent gets a new state, and a reward/punishment\n",
    "\n",
    "**markov decision process**: model for decision-making, representing states, actions, and their rewards\n",
    "\n",
    "- set of states `S`\n",
    "- set of actions `Actions(s)`\n",
    "- transition model `P(s'|s,a)`\n",
    "- reward function `R(s, a, s')`\n",
    "\n",
    "**Q-learning**: method for learning a function $Q(s, a)$, estimate of the value of performing action $a$ in the state $s$\n",
    "\n",
    "- start with $Q(s,a)=0$ for all $s,a$\n",
    "- when we have taken an action and recieved a reward:\n",
    "    - estimate the value of $Q(s,a)$ based on current reward and expected future rewards\n",
    "    - update $Q(s,a)$ to take into account old estimate as well as our new estimate\n",
    "\n",
    "however this Q-learning has some issues\n",
    "- explore vs exploit\n",
    "    - exploit: using the knowledge it already has\n",
    "    - explore: exploring new actions\n",
    "    - by only using the knowledge, it might stick to a sub-optimal path to the goal\n",
    "\n",
    "this can be solved with **$\\varepsilon$-greedy**\n",
    "\n",
    "- set $\\varepsilon$ equal to how often we want to move randomly\n",
    "- with probability $1-\\varepsilon$, choose the estimated best move\n",
    "- with probability $\\varepsilon$, choose a random move\n",
    "\n",
    "**function approximation**: approximating $Q(s,a)$, often by a function combining various features, rather than storing one value for every state-action pair\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## unsupervised learning\n",
    "\n",
    "given input data without any additional feedback, learn patterns\n",
    "\n",
    "**clustering**: organising a set of objects into groups in such a way that similar objects tend to be in the same group\n",
    "\n",
    "**k-means clustering**: algorithm for clustering data based on repeatedly assigning points to clusters and updating those cluster's centers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}