{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# week 5: neural networks\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## artificial neural networks\n",
    "\n",
    "- model mathematical function from inputs to outputs based on the structure and parameters of the network\n",
    "- allows for learning the network's parameters based on data\n",
    "\n",
    "### activation functions\n",
    "\n",
    "- step function\n",
    "  - $g(x)=1$ if $x\\ge0$ else $0$\n",
    "  - forms a step at $\\vec w\\cdot\\vec x$\n",
    "- logistic sigmoid\n",
    "  - $g(x)=e^x/e^x+1$\n",
    "  - forms a probability sigmoid around $\\vec w\\cdot\\vec x$\n",
    "- ReLU\n",
    "  - $g(x)=\\text{max}(0, g)$\n",
    "  - forms a hockey stick starting at $\\vec w\\cdot\\vec x$\n",
    "\n",
    "These activation functions effectively result in\n",
    "$\n",
    "h(x_1,x_2)=g(w_0+w_1x_1+w_2x_2)\n",
    "$\n",
    "\n",
    "### network structure\n",
    "\n",
    "#### OR function\n",
    "\n",
    "- $w_0=-1$\n",
    "- $w_1=1$\n",
    "- $w_2=1$\n",
    "- $g(-1+1x_1+1x_2)$\n",
    "- step activation function\n",
    "\n",
    "#### AND function\n",
    "\n",
    "- $w_0=-2$\n",
    "- $w_1=1$\n",
    "- $w_2=1$\n",
    "- $g(-2+1x_1+1x_2)$\n",
    "- step activation function\n",
    "\n",
    "### multiple nodes\n",
    "\n",
    "$\n",
    "g(\\sum^n_{i=1}x_iw_1+w_0)\n",
    "$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## training: gradient descent\n",
    "\n",
    "- algorithm for minimising loss when training a neural network\n",
    "\n",
    "1. start with a random choice of weights\n",
    "2. repeat\n",
    "   1. calculate the gradient based on all data points: direction that will lead to decreasing loss\n",
    "   2. update weights according to the gradient\n",
    "\n",
    "- calculating from all data points is very  (in terms of time and effort)\n",
    "- so somtimes we use one data point only\n",
    "- or sometimes use a small batch\n",
    "\n",
    "### binary classification\n",
    "\n",
    "- we can only predict things that are linearly seperable\n",
    "- **a single perceptron is only capable of learning a linearly seperable decision boundary**\n",
    "- how do we make more complex decision bounaries, such as circular?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## multilayer neural network\n",
    "\n",
    "- an ANN with an input layer, output layer, and at least one hidden layer\n",
    "- Input -> hidden -> Output\n",
    "- this can model more complex functions\n",
    "- if you know the loss of the output node, you can estimate the loss contribution from the hidden layer from the weights - backpropogation\n",
    "  - start with a random choice of weights\n",
    "  - repeat:\n",
    "    - calculate error for output layer\n",
    "    - for every layer, starting with output layer and moving back towards the earliest hidden layer:\n",
    "      - propogate error back one layer\n",
    "      - update weights\n",
    "- this is a **deep neural network**, an ANN with multiple hidden layers\n",
    "\n",
    "### overfiting\n",
    "\n",
    "to combat overfitting with DNNs, we can use **dropout**\n",
    "\n",
    "- temporarily removing units, selected at random, from an ANN to prevent over-reliance on certain units\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read data from file\n",
    "with open(\"banknotes.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    data = []\n",
    "    for row in reader:\n",
    "        data.append({\n",
    "            \"evidence\": [float(cell) for cell in row[:4]],\n",
    "            \"label\": 1 if row[4] == \"0\" else 0\n",
    "        })\n",
    "\n",
    "# separate data into train and test sets\n",
    "evidence = [row[\"evidence\"] for row in data]\n",
    "labels = [row[\"label\"] for row in data]\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(evidence, labels, test_size=0.4)\n",
    "\n",
    "# create a neural network\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# add a hidden layer with 8 units, with ReLU activation function\n",
    "model.add(tf.keras.layers.Dense(8, input_shape=(4,), activation=\"relu\"))\n",
    "\n",
    "# add output layer with 1 unit, with sigmoid activation function\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# train neural network with adam optimiser, binarised crossentropy loss and accuracy metric\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# fit the model with 20 epochs\n",
    "model.fit(X_training, y_training, epochs=20)\n",
    "\n",
    "# evaluate model performance\n",
    "model.evaluate(X_testing, y_testing, verbose=2)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 1.3390 - accuracy: 0.2848\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.1499 - accuracy: 0.3618\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.8908 - accuracy: 0.4436\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.7555 - accuracy: 0.4994\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.5895\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.6823\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7707\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8407\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8799\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.3202 - accuracy: 0.9201\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.9606\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.9619\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9667\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2091 - accuracy: 0.9695\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1813 - accuracy: 0.9768\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9792\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9944\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9837\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9922\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1342 - accuracy: 0.9921\n",
      "18/18 - 0s - loss: 0.1187 - accuracy: 0.9945\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.118703693151474, 0.994535505771637]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## computer vision\n",
    "\n",
    "- computational methods for analysing and understanding digital images\n",
    "- flattening out an image into pixel strings removes a lot of useful information\n",
    "  \n",
    "### image convolution\n",
    "\n",
    "#### kernels\n",
    "\n",
    "- applying a filter that adds each pixel value of an image according to its neighbors, weighted according to a kernel matrix\n",
    "- example kernel:\n",
    "  - [0, -1, 0]\n",
    "  - [-1, 5, -1]\n",
    "  - [0, -1, 0]\n",
    "  - or\n",
    "  - [-1, -1, -1]\n",
    "  - [-1, 8, -1]\n",
    "  - [-1, -1, -1]\n",
    "\n",
    "#### pooling\n",
    "\n",
    "- reducing the size of an input by sampling from regions in the input\n",
    "- max-pooling: pooling by choosing the maximum value in a region\n",
    "\n",
    "### convolutional neural network\n",
    "\n",
    "- neural networks that use convolution, usually for analysing images\n",
    "- convolution -> pooling -> deep neural network\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## types of ANNs\n",
    "\n",
    "### feed-forward neural network\n",
    "\n",
    "- neural network that has connections only in one direction\n",
    "\n",
    "### recurrent neural network\n",
    "\n",
    "- network can maintain a state and feed back to itself\n",
    "- this is a one-to-many structure\n",
    "- it can output at each step (such as building up a sentence from an image)\n",
    "- or it can just pass the old network as new inputs (such as analysing an entire video image-by-image)\n",
    "- or it can be many-to-many, such as google translate where it can't just translate word-by-word, with a Long Short-Term Memory Network (LSTM)\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('py39': conda)"
  },
  "interpreter": {
   "hash": "88b11310c3bf316e37a708cb8d0dbf79bba9a2d571f5024d0d39a9df939cbe1c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}