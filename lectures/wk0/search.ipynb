{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# week 0: search\n",
    "\n",
    "## definitions\n",
    "\n",
    "**Agent**: An entity that perceives its environment and acts upon that environment. In a navigator app, for example, the agent would be a representation of a car that needs to decide on which actions to take to arrive at the destination.\n",
    "\n",
    "**State**: A configuration of an agent in its environment. For example, in a 15 puzzle, a state is any one way that all the numbers are arranged on the board.\n",
    "\n",
    "**Initial State**: The state from which the search algorithm starts. In a navigator app, that would be the current location.\n",
    "\n",
    "**Actions**: Choices that can be made in a state. More precisely, actions can be defined as a function. Upon receiving state s as input, `Actions(s)` returns as output the set of actions that can be executed in state `s`. For example, in a 15 puzzle, the actions of a given state are the ways you can slide squares in the current configuration (4 if the empty square is in the middle, 3 if next to a side, 2 if in the corner).\n",
    "\n",
    "**Transition Model**: A description of what state results from performing any applicable action in any state. More precisely, the transition model can be defined as a function. Upon receiving state s and action a as input, `Results(s, a)` returns the state resulting from performing action `a` in state `s`. For example, given a certain configuration of a 15 puzzle (state s), moving a square in any direction (action `a`) will bring to a new configuration of the puzzle (the new state).\n",
    "\n",
    "**State Space**: The set of all states reachable from the initial state by any sequence of actions. For example, in a 15 puzzle, the state space consists of all the 16!/2 configurations on the board that can be reached from any initial state. The state space can be visualized as a directed graph with states, represented as nodes, and actions, represented as arrows between nodes.\n",
    "\n",
    "**Goal Test**: The condition that determines whether a given state is a goal state. For example, in a navigator app, the goal test would be whether the current location of the agent (the representation of the car) is at the destination. If it is — problem solved. If it’s not — we continue searching.\n",
    "\n",
    "**Path Cost**: A numerical cost associated with a given path. For example, a navigator app does not simply bring you to your goal; it does so while minimizing the path cost, finding the fastest way possible for you to get to your goal state.\n",
    "\n",
    "## search problems\n",
    "\n",
    "- initial state\n",
    "- actions\n",
    "- transition model\n",
    "- goal test\n",
    "- path cost function\n",
    "\n",
    "**Solution**: A sequence of actions that leads from the initial state to a goal state -> **Optimal**: Lowest path cost\n",
    "\n",
    "## data structure\n",
    "\n",
    "**Node**: A data structure that keeps track of:\n",
    "- a state\n",
    "- a parent (node that generated this node)\n",
    "- an action (applied to parent to get to this node)\n",
    "- a path cost (from initial state to node)\n",
    "\n",
    "**Frontier**: All of the next nodes that we could take that we haven't yet\n",
    "\n",
    "## solutions\n",
    "\n",
    "- Start with a frontier that contains the initial state\n",
    "- Repeat:\n",
    "    1. If the frontier is empty: there is no solution\n",
    "    2. Remove a node from the frontier\n",
    "    3. If that node is the goal, return the solution\n",
    "    4. Expand the node, and add resulting nodes to the frontier (the neighbouring nodes)\n",
    "\n",
    "## revised approach\n",
    "\n",
    "1. If the frontier is empty,\n",
    "    - Stop. There is no solution to the problem.\n",
    "2. Remove a node from the frontier. This is the node that will be considered.\n",
    "3. If the node contains the goal state,\n",
    "    - Return the solution. Stop.\n",
    "4. Else,\n",
    "    - Expand the node (find all the new nodes that could be reached from this node), and add resulting nodes to the frontier, if they aren't in the frontier or the explored set.\n",
    "    - Add the current node to the explored set.\n",
    "\n",
    "How do we choose which node to remove?\n",
    "\n",
    "**Stack**: LIFO data type\n",
    "- The most recent addition to the stack is the first one removed\n",
    "- Producdes a **Depth First Search (DFS)**\n",
    "- Fastest if lucky\n",
    "- Slowest if unlucky\n",
    "- Could choose bad paths\n",
    "\n",
    "**Queue**: FIFO data type\n",
    "- The first addition (oldest) to the stack is the first one removed\n",
    "- Produces a **Breadth First Search (BFS)**\n",
    "- Always finds the optimal solution\n",
    "- Almost always takes longer than the minimum solution time\n",
    "- At worst, takes the longest\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    " ## DFS Stack\n",
    " \n",
    " # Define the function that removes a node from the frontier and returns it.\n",
    "    def stack_remove(self):\n",
    "    \t  # Terminate the search if the frontier is empty, because this means that there is no solution.\n",
    "        if self.empty():\n",
    "            raise Exception(\"empty frontier\")\n",
    "        else:\n",
    "        \t  # Save the last item in the list (which is the newest node added)\n",
    "            node = self.frontier[-1]\n",
    "            # Save all the items on the list besides the last node (i.e. removing the last node)\n",
    "            self.frontier = self.frontier[:-1]\n",
    "            return node\n",
    "\n",
    "## BFS Queue\n",
    "\n",
    "# Define the function that removes a node from the frontier and returns it.\n",
    "def queue_remove(self):\n",
    "        # Terminate the search if the frontier is empty, because this means that there is no solution.\n",
    "    if self.empty():\n",
    "        raise Exception(\"empty frontier\")\n",
    "    else:\n",
    "        # Save the oldest item on the list (which was the first one to be added)\n",
    "        node = self.frontier[0]\n",
    "        # Save all the items on the list besides the first one (i.e. removing the first node)\n",
    "        self.frontier = self.frontier[1:]\n",
    "        return node"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## more search types\n",
    "\n",
    "**Uninformed Search**: Uses no problem-specific knowledge i.e. DFS, BFS\n",
    "\n",
    "**Informed Search**: A stratergy that uses problem-specific knowledge to find more efficient solutions\n",
    "\n",
    "**Greedy Best-First Search**: GBFS expands the node closest to the goal, by using an esimate heuristic function `h(n)`\n",
    "- **Manhattan Distance** is a heuristic to estimate the path length from a node to the goal, ignoring the walls, by a straight x and y path (because it looks like manhattan streets)\n",
    "- GBFS does not always find the most efficient path, as heuristics are local\n",
    "\n",
    "**A\\* Search**: A-Star expands the node with the lowest value of `g(n)+h(n)`, where: \n",
    "- `g(n)` is the cost to reach that node\n",
    "- `h(n)` (the heuristic) is the estimated cost to the goal\n",
    "- A\\* is optimal **if**\n",
    "    - `h(n)` is admissable - never overestimates the true cost\n",
    "    - `h(n)` is consistent - for every node `n` and successor `n'` with step cost `c`, `h(n)`<=`h(n')+c`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## multi-agent problems - adversarial\n",
    "\n",
    "**Minimax**: we can codify a game of tic-tac-toe: O win is `-1`, draw is `0`, X win is `+1`\n",
    "- **`MAX (X)`** wants to maximise the score\n",
    "- **`MIN (O)`** wants to minimise the score\n",
    "- `S0` initial state\n",
    "- `Player(s)` returns which player is next\n",
    "- `Actions(s)` returns legal moves in state `s`\n",
    "- `Result(s, a)` returns the state after action `a` is taken in state `s`\n",
    "- `Terminal(s)` checks if state `s` is terminal (win or draw)\n",
    "- `Utility(s)` returns the final numerical value for terminal state `s`\n",
    "    - X wins = 1\n",
    "    - O wins = -1\n",
    "    - Draw = 0\n",
    "\n",
    "Given a state `s`:\n",
    "- MAX picks an action `a` in `Actions(s)` that produces the higest value of `Min-Value(Result(s, a))`\n",
    "- MIN picks an action `a` in `Actions(s)` that produces the lowest value of `Max-Value(Result(s, a))`\n",
    "\n",
    "`Max-Value(state)`:\n",
    "- If `Terminal(state)`:\n",
    "    - Return `Utility(state)`\n",
    "- Else:\n",
    "    - `v` = `-Infinity`\n",
    "    - For each `action` in `Actions(state)`:\n",
    "        - `v` = `Max(v, Min-Value(Result(state, action)))`\n",
    "    - Return `v`\n",
    "\n",
    "`Min-Value(state)`:\n",
    "- If `Terminal(state)`:\n",
    "    - Return `Utility(state)`\n",
    "- Else:\n",
    "    - `v` = `+Infinity`\n",
    "    - For each `action` in `Actions(state)`:\n",
    "        - `v` = `Min(v, Max-Value(Result(state, action)))`\n",
    "    - Return `v`\n",
    "\n",
    "## optimisations\n",
    "\n",
    "**Alpha-Beta Pruning**: when exploring scores from following nodes, if you identify one node with at least one worse score (lower than other nodes if you are MAX), disregard that node as it cannot be optimal\n",
    "\n",
    "**Depth-Limited Minimax**: after a certain number of moves, Minimax will stop\n",
    "- To score a board at maximum depth, we add an `Evaluation(state)` to estimate the expected utility of the game from a given state\n",
    "- Optimising this evaluation makes a better AI\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}